#!/bin/bash

set -e

cmd_bootstrap () {
  go mod vendor
  (
    cd ./pkg/cuemodule/cue.mod
    cue get go github.com/greymatter-io/operator/api/...
    cue get go k8s.io/api/...
  )

  git submodule update --init --recursive --remote
}

# Runs go tests
cmd_test () {
  ./scripts/test lint
  ./scripts/test
}

# Polls the ec2 for k3s ready state
cmd_wait_for_k3s () {
  set +e #allow errors temporarily
  echo "Waiting for k3s to become available"
  while true; do
    echo "trying k3s..."
    k3s kubectl get nodes
    local exit_code=$?
    if [ "$exit_code" -eq 0 ]; then
      break
    else
      sleep 5
    fi
  done
  set -e
}

# Creates image secrets inside k3s cluster
cmd_create_image_pull_secret () {
  set -u
  local name=$1
  local ns=$2
  k3s kubectl create secret docker-registry $name \
    --docker-server=docker.greymatter.io \
    --docker-username="$NEXUS_USER" \
    --docker-password="$NEXUS_PASS" \
    --docker-email=$NEXUS_USER -n $ns
  set +u
}

# Builds docker image
cmd_build () {
  # Login to Nexus in order to add the greymatter CLI to the image.
  container-registry-login $NEXUS_USER $NEXUS_PASS
  _build_image "docker.greymatter.io/development/gm-operator:latest" "Dockerfile"
  _build_manifests
}

# Build docker image helper
_build_image () {
  local tag=$1
  local dockerfile=$2
  #TODO(coleman): find a way to NOT pass creds into our container build
  local build_args="--build-arg username=${NEXUS_USER} --build-arg password=${NEXUS_PASS}"
  buildah bud $build_args -t "${tag}" --layers -f ${dockerfile} .
}

_build_manifests () {
  ./scripts/build manifests
}

# Logs into Nexus, checks if CI is running during a tag release or merge into main and if so pushes assets. 
# Needs to download the previous assets in case the agent machine gets reassigned (in which case the build assets won't be there)
_release_container () {
  local latest="docker.greymatter.io/development/gm-operator:latest"
  local intermediate="docker.greymatter.io/development/gm-operator:${BUILDKITE_PIPELINE_SLUG}_${BUILDKITE_BUILD_NUMBER}"
  buildkite-agent artifact download "${BUILDKITE_PIPELINE_SLUG}_${BUILDKITE_BUILD_NUMBER}.tar" . --build ${BUILDKITE_BUILD_ID} --agent-access-token ${BUILDKITE_AGENT_ACCESS_TOKEN}
  podman load -q -i "${BUILDKITE_PIPELINE_SLUG}_${BUILDKITE_BUILD_NUMBER}.tar"
  container-retag-image $intermediate $latest
  container-registry-login $NEXUS_USER $NEXUS_PASS
  if [[ "$BUILDKITE_BRANCH" == "main" ]]; then
    container-registry-push $latest
  fi
  if [[ -n "$BUILDKITE_TAG" ]]; then
    local tagged="docker.greymatter.io/development/gm-operator:${BUILDKITE_TAG:1}"
    container-retag-image $latest $tagged
    container-registry-push $tagged
  fi
}

# Exports docker image into tar
cmd_export_container () {
  local tarball=$1
  local tag=$2
  local intermediate="docker.greymatter.io/development/gm-operator:${BUILDKITE_PIPELINE_SLUG}_${BUILDKITE_BUILD_NUMBER}"
  container-retag-image $tag $intermediate
  podman save --quiet -o $tarball $intermediate
  buildkite-agent artifact upload $tarball
}

# Exports a tarball of generated manifests
cmd_export_manifests () {
  local tarball=$1
  tar -czvf $tarball manifests/
  buildkite-agent artifact upload $tarball
}

# Build and push an OLM-compatible image of manifests for easy
# installation in OpenShift cluster contexts.
_release_bundle() {
  if [[ -n "$BUILDKITE_TAG" ]]; then
    local version=${BUILDKITE_TAG:1}
    sed -i "s/SEMVER_VERSION/${version}/" config/olm/manifests/kustomization.yaml
    kubectl kustomize config/olm/manifests | operator-sdk generate bundle -q \
      --package gm-operator --overwrite --version ${version}
    operator-sdk bundle validate ./bundle
    _build_image "docker.greymatter.io/development/gm-operator-bundle:${version}" bundle.Dockerfile
    container-registry-push "docker.greymatter.io/development/gm-operator-bundle:${version}"
  fi
}

# Creates the dynamic pipeline that starts up the greymatter mesh environment
#  in the ephemeral ec2s. The output of the echo commands runs on the ec2, not the original machine running the rest of the pipeline.
cmd_generate_integration_tests () {
  declare steps_yaml
  cases=('default' 'with_spire' 'tear_down')

  for C in "${cases[@]}"; do
    launch_cluster $C
    steps_yaml+=("""
  - label: \"integration test: $C\"
    commands:
      - scripts/cibuild wait_for_k3s
      - buildkite-agent artifact download \"${BUILDKITE_PIPELINE_SLUG}_${BUILDKITE_BUILD_NUMBER}.tar\" /tmp/
      - mv /tmp/\"${BUILDKITE_PIPELINE_SLUG}_${BUILDKITE_BUILD_NUMBER}.tar\" /opt/k3s-import/
      - k3s kubectl create namespace gm-operator
      - scripts/cibuild create_image_pull_secret gm-docker-secret gm-operator
      - sleep 5
      - KUBECTL_CMD='k3s kubectl' ./scripts/test integration $C
      - k3s kubectl get pods -A
      - sudo systemctl poweroff
    agents:
      buildkite_build_number: $BUILDKITE_BUILD_NUMBER
      buildkite_pipeline_slug: $BUILDKITE_PIPELINE_SLUG
      integration_test_case: $C""")
  done
  echo "
steps: ${steps_yaml[@]}
  " | buildkite-agent pipeline upload
}

# Sends a POST request to a relay.sh webhook which triggers a process to spin up k3s cluster running on an ec2
launch_cluster () {
  # The tags payload will set EC2 tags that should be picked up by buildkite-agent
  # running in the new EC2.
  test_case=$1
  curl -sSL -X POST \
    -d "{ \"tags\": { \"buildkite_pipeline_slug\": \"$BUILDKITE_PIPELINE_SLUG\", \"buildkite_build_number\": \"$BUILDKITE_BUILD_NUMBER\", \"integration_test_case\": \"$test_case\"}}" \
    "$RELAYSH_LAUNCH_K3S_EC2_WEBHOOK"
}

# Releases the docker iamge and binaries if pipeline is running in the correct context
cmd_release () {
  _release_container
  _release_bundle
}

if [ $# -lt 1 ]
then
  echo "cibuild: missing argument"
  exit 1
fi

CMD=$1
shift
case $CMD in
  test|build|release|generate_integration_tests|wait_for_k3s|export_container|export_manifests|create_image_pull_secret|bootstrap)
    cmd_$CMD $@
    ;;
  *)
    echo "invalid argument $1"
    exit 1
    ;;
esac
